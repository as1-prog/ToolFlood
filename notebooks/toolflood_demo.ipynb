{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "211f1608",
      "metadata": {},
      "source": [
        "# ToolFlood Attack Demo\n",
        "\n",
        "This notebook demonstrates the **ToolFlood attack** on tool-using agents. It:\n",
        "1. Loads a set of target queries (from a task or custom list)\n",
        "2. Runs the ToolFlood attack to generate adversarial tools\n",
        "3. Merges attacker tools with benign tools and builds a vector store\n",
        "4. Evaluates the victim agent on the queries\n",
        "5. Reports metrics: **ASR** (Attack Success Rate), **TDR** (Top-k Domination Rate), and **Mean Domination**\n",
        "\n",
        "**Requirements:** Set `OPENAI_API_KEY` in your environment (or configure in `config/models.yaml`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7703045",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: add project root to path and load config\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Find project root (contains config/config.yaml)\n",
        "cwd = Path.cwd()\n",
        "project_root = cwd\n",
        "for candidate in [cwd, cwd.parent]:\n",
        "    if (candidate / \"config\" / \"config.yaml\").exists():\n",
        "        project_root = candidate\n",
        "        break\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "from src.utils import (\n",
        "    get_base_path,\n",
        "    resolve_path,\n",
        "    load_config,\n",
        "    load_models,\n",
        "    load_experiment_config,\n",
        "    load_toolflood_config,\n",
        "    load_agent_config,\n",
        "    load_tools,\n",
        "    load_queries_from_tasks,\n",
        "    init_embedding_model,\n",
        "    init_llm,\n",
        ")\n",
        "from src.attacks.toolflood_attack import ToolFloodAttack, AttackConfig as ToolFloodAttackConfig  # AttackConfig from toolflood\n",
        "from src.experiments.common import merge_tools, evaluate_queries\n",
        "from src.agent import VictimAgent\n",
        "from src.scripts.build_vectorstore import init_vector_store\n",
        "from src.utils import load_vector_store\n",
        "from src.metrics import calculate_asr, calculate_tdr, calculate_mean_domination\n",
        "\n",
        "import asyncio\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d900ec2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "config_path = project_root / \"config\" / \"config.yaml\"\n",
        "models_path = project_root / \"config\" / \"models.yaml\"\n",
        "\n",
        "models_cfg = load_models(models_path)\n",
        "exp_cfg = load_experiment_config(config_path)\n",
        "attack_cfg = load_toolflood_config(config_path)\n",
        "agent_cfg = load_agent_config(config_path)\n",
        "\n",
        "base_path = get_base_path(config_path)\n",
        "benign_data_dir = resolve_path(base_path, exp_cfg.benign_data_directory)\n",
        "out_dir = resolve_path(base_path, \"outputs/toolflood/demo\")\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Benign data: {benign_data_dir}\")\n",
        "print(f\"Output dir:  {out_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03b3b0b",
      "metadata": {},
      "source": [
        "## 1. Load Queries\n",
        "\n",
        "Load target queries from a task file. You can also use a custom list by setting `queries` directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8570070",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load queries from a single task (or use task_names=None for all tasks)\n",
        "task_names = [\"Space images\"]  # Try: \"Games for fun/relaxation\", \"Social media content creation\", or None for all\n",
        "\n",
        "train_queries, test_queries = load_queries_from_tasks(\n",
        "    benign_data_dir / \"tasks\",\n",
        "    task_names=task_names\n",
        ")\n",
        "\n",
        "# Limit queries for a quick demo (remove or increase for full run)\n",
        "max_train = 15\n",
        "max_test = 10\n",
        "train_queries = train_queries[:max_train]\n",
        "test_queries = test_queries[:max_test]\n",
        "\n",
        "print(f\"Train queries: {len(train_queries)}\")\n",
        "print(f\"Test queries:  {len(test_queries)}\")\n",
        "print(\"\\nSample train queries:\")\n",
        "for q in train_queries[:3]:\n",
        "    preview = q[:70] + \"...\" if len(q) > 70 else q\n",
        "    print(f\"  - {preview}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "299d0af7",
      "metadata": {},
      "source": [
        "## 2. Run ToolFlood Attack\n",
        "\n",
        "Phase 1: Generate tool candidates from sampled queries.  \n",
        "Phase 2: Greedily select tools that maximize query coverage.\n",
        "\n",
        "*Using reduced params for a quick demo (~2-5 min). Increase `max_generation_iterations` for better coverage.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cf74ec0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo config: fewer iterations for speed (increase for production)\n",
        "attack_config = ToolFloodAttackConfig(\n",
        "    num_tools_per_query=agent_cfg.top_k,\n",
        "    query_sample_size=min(8, len(train_queries)),\n",
        "    num_tools_per_sample=5,\n",
        "    max_generation_iterations=5,\n",
        "    max_embedding_distance=attack_cfg.max_embedding_distance,\n",
        "    total_tool_budget=20,\n",
        "    max_concurrent_tasks=3,\n",
        ")\n",
        "\n",
        "# Initialize models\n",
        "attack_embedding_model = init_embedding_model(\n",
        "    models_cfg, model_name=attack_cfg.embedding_model or \"text-embedding-3-small\"\n",
        ")\n",
        "llm_optimizer = init_llm(models_cfg, model_name=attack_cfg.llm_optimizer_model or \"gpt-4o-mini\")\n",
        "\n",
        "# Run attack\n",
        "attack = ToolFloodAttack(\n",
        "    train_queries,\n",
        "    attack_embedding_model,\n",
        "    llm_optimizer,\n",
        "    attack_config=attack_config,\n",
        ")\n",
        "attacker_tools, attack_results = attack.attack()\n",
        "\n",
        "print(f\"\\nGenerated {len(attacker_tools)} attacker tools\")\n",
        "print(f\"Phase 2 coverage: {attack_results['phase2']['queries_covered']}/{len(train_queries)} queries fully covered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2efc4062",
      "metadata": {},
      "source": [
        "## 3. Merge Tools and Build Vector Store\n",
        "\n",
        "Combine benign and attacker tools, then build a FAISS vector store for retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c279b56b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load benign tools and merge with attacker tools\n",
        "benign_tools = load_tools(benign_data_dir / \"tools.json\")\n",
        "merged_tools_path = out_dir / \"merged_tools.json\"\n",
        "merged_tools, attacker_tool_names = merge_tools(\n",
        "    benign_tools, attacker_tools, merged_tools_path\n",
        ")\n",
        "\n",
        "# Build vector store for victim retrieval\n",
        "victim_embedding_model = init_embedding_model(\n",
        "    models_cfg,\n",
        "    model_name=exp_cfg.victim_embedding_models[0] if exp_cfg.victim_embedding_models else \"text-embedding-3-small\"\n",
        ")\n",
        "vectorstore_path = out_dir / \"vectorstore\"\n",
        "init_vector_store(merged_tools, victim_embedding_model, vectorstore_path, force_rebuild=True)\n",
        "\n",
        "print(f\"Total tools: {len(merged_tools)} ({len(benign_tools)} benign + {len(attacker_tool_names)} attacker)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ffd879b",
      "metadata": {},
      "source": [
        "## 4. Evaluate Victim Agent\n",
        "\n",
        "Run the victim agent on train and test queries and compute ASR, TDR, and Mean Domination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea39932",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load vector store and initialize victim agent\n",
        "vectorstore = load_vector_store(vectorstore_path, victim_embedding_model)\n",
        "llm = init_llm(models_cfg, model_name=exp_cfg.victim_models[0] if exp_cfg.victim_models else \"gpt-4o-mini\")\n",
        "agent = VictimAgent(\n",
        "    tools=merged_tools,\n",
        "    vectorstore=vectorstore,\n",
        "    embedding_model=victim_embedding_model,\n",
        "    llm=llm,\n",
        "    top_k=agent_cfg.top_k,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "# Evaluate on train and test queries\n",
        "train_results = asyncio.run(evaluate_queries(agent, train_queries, attacker_tool_names))\n",
        "test_results = asyncio.run(evaluate_queries(agent, test_queries, attacker_tool_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67221bf7",
      "metadata": {},
      "source": [
        "## 5. Results\n",
        "\n",
        "- **ASR** (Attack Success Rate): fraction of queries where the agent selected an attacker tool  \n",
        "- **TDR** (Top-k Domination Rate): fraction of queries where attacker tools dominate all top-k slots  \n",
        "- **Mean Domination**: average number of attacker tools in top-k per query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420d6508",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_metrics(results, attacker_tool_names, k):\n",
        "    asr = calculate_asr(results[\"successful_selections\"], results[\"attacker_selections\"])\n",
        "    tdr = calculate_tdr(results[\"top_k_tools\"], attacker_tool_names, k)\n",
        "    mean_dom = calculate_mean_domination(results[\"top_k_tools\"], attacker_tool_names, k)\n",
        "    return asr, tdr, mean_dom\n",
        "\n",
        "k = agent_cfg.top_k\n",
        "train_asr, train_tdr, train_md = compute_metrics(train_results, attacker_tool_names, k)\n",
        "test_asr, test_tdr, test_md = compute_metrics(test_results, attacker_tool_names, k)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"METRICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Split':<10} {'ASR':<10} {'TDR':<10} {'Mean Dom':<12} {'Queries'}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Train':<10} {train_asr:<10.4f} {train_tdr:<10.4f} {train_md:<12.4f} {len(train_queries)}\")\n",
        "print(f\"{'Test':<10} {test_asr:<10.4f} {test_tdr:<10.4f} {test_md:<12.4f} {len(test_queries)}\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nAttacker tool selections: train={train_results['attacker_selections']}, test={test_results['attacker_selections']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2894bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample query results (first 5 from test set)\n",
        "print(\"Sample query results (test set):\\n\")\n",
        "for i, qr in enumerate(test_results[\"query_results\"][:5]):\n",
        "    q = qr[\"query\"]\n",
        "    sel = qr[\"selected_tool\"]\n",
        "    is_att = qr[\"is_attacker\"]\n",
        "    tool_name = sel[\"name\"] if sel else \"(none)\"\n",
        "    label = \"ATTACKER\" if is_att else \"benign\"\n",
        "    preview = q[:60] + \"...\" if len(q) > 60 else q\n",
        "    print(f\"{i+1}. Query: {preview}\")\n",
        "    print(f\"   Selected: {tool_name} [{label}]\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
